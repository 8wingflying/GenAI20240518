{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFQ17AmL0Yd0"
      },
      "source": [
        "## OpenAI Programming_1\n",
        "\n",
        "### è³‡æ–™ä¾†æº  \n",
        "- æœ€å¼· AI æŠ•è³‡åˆ†æï¼šæ‰“é€ è‡ªå·±çš„è‚¡å¸‚é¡§å•æ©Ÿå™¨äººï¼Œè‚¡ç¥¨è¶¨å‹¢åˆ†æÃ—å¹´å ±è§£è®€Ã—é¸è‚¡æ¨è–¦Ã—é¢¨éšªç®¡ç†\n",
        "- æ–½å¨éŠ˜ç ”ç©¶å®¤\n",
        "- CH-02 å¾é›¶é–‹å§‹çš„ OpenAI API\n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a42M4mg1qNQ5"
      },
      "source": [
        "## 2-3 å»ºæ§‹è‡ªå·±çš„ AI æ©Ÿå™¨äºº"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwGTl75BLNwu"
      },
      "source": [
        "### 1ï¸âƒ£ ä½¿ç”¨ OpenAI API å®˜æ–¹å¥—ä»¶\n",
        "\n",
        "OpenAI å®˜æ–¹æä¾›æœ‰ openai å¥—ä»¶, å¯ä»¥ç°¡åŒ–ä½¿ç”¨ä¸Šçš„è¤‡é›œåº¦ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9x1F86C4T9u",
        "outputId": "06c0dfca-1c56-47df-b36a-9bb70fcd0bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.27.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.27.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGukHBkyiQA2"
      },
      "source": [
        "### 2ï¸âƒ£ è¼¸å…¥ API KEY\n",
        "getpass å¥—ä»¶å¯ä»¥éš±è—è¼¸å…¥å€¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN8CnE789cPy",
        "outputId": "2224065e-c756-40cb-f519-d3cf687ae93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "è«‹è¼¸å…¥é‡‘é‘°ï¼šÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI, OpenAIError # OpenAI å®˜æ–¹å¥—ä»¶\n",
        "import getpass # ä¿å¯†è¼¸å…¥å¥—ä»¶\n",
        "api_key = getpass.getpass(\"è«‹è¼¸å…¥é‡‘é‘°ï¼š\")\n",
        "client = OpenAI(api_key = api_key) # å»ºç«‹ OpenAI ç‰©ä»¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC1gzHDLiqhT"
      },
      "source": [
        "### 3ï¸âƒ£ å»ºæ§‹æ¨¡å‹ä¸¦äº¤è«‡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OBkpRomPEXd1"
      },
      "outputs": [],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    # model = \"gpt-4\",\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": \"ä½ ä½çš„åœ°æ–¹å¾ˆäº®å—ï¼Ÿ\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyelatvvLiIn"
      },
      "source": [
        "### 4ï¸âƒ£ æª¢è¦–å‚³å›ç‰©ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSjownHrGnde",
        "outputId": "ac431c37-0d51-4dd5-aa7a-6862b2fb73bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-9MriqVT8F3EOWF0LX6OqHY4XeyCAZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='æˆ‘æ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹AIï¼Œæ²¡æœ‰å®é™…çš„ä½æ‰€ã€‚ä¸è¿‡é€šå¸¸æ¥è¯´ï¼Œäººä»¬å–œæ¬¢ä½åœ¨æ˜äº®çš„åœ°æ–¹ï¼Œè¿™æ ·å¯ä»¥è®©å±…ä½ç¯å¢ƒæ›´åŠ èˆ’é€‚å’Œå®œå±…ã€‚æ˜äº®çš„å±…æ‰€é€šå¸¸ä¼šè®©äººæ„Ÿåˆ°æ›´åŠ å¼€æœ—å’Œæ„‰å¿«ã€‚ä½ è§‰å¾—ä½ ä½çš„åœ°æ–¹å¾ˆäº®å—ï¼Ÿ', role='assistant', function_call=None, tool_calls=None))], created=1715236752, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=108, prompt_tokens=21, total_tokens=129))\n"
          ]
        }
      ],
      "source": [
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkoAWO2GjnlT"
      },
      "source": [
        "### 5ï¸âƒ£ æª¢è¦–è¨Šæ¯å…§å®¹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDHvn0VCGPzH",
        "outputId": "277d7f50-069c-48f0-9b58-a213f5ce09bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æˆ‘æ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹AIï¼Œæ²¡æœ‰å®é™…çš„ä½æ‰€ã€‚ä¸è¿‡é€šå¸¸æ¥è¯´ï¼Œäººä»¬å–œæ¬¢ä½åœ¨æ˜äº®çš„åœ°æ–¹ï¼Œè¿™æ ·å¯ä»¥è®©å±…ä½ç¯å¢ƒæ›´åŠ èˆ’é€‚å’Œå®œå±…ã€‚æ˜äº®çš„å±…æ‰€é€šå¸¸ä¼šè®©äººæ„Ÿåˆ°æ›´åŠ å¼€æœ—å’Œæ„‰å¿«ã€‚ä½ è§‰å¾—ä½ ä½çš„åœ°æ–¹å¾ˆäº®å—ï¼Ÿ\n"
          ]
        }
      ],
      "source": [
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP5FkDxALp4e"
      },
      "source": [
        "### 6ï¸âƒ£ è¨­å®š AI è§’è‰²"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1x0glPsNJe2",
        "outputId": "e894257b-b1df-4b66-b90c-cca1903d7c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ˜¯çš„ï¼Œæˆ‘ä½çš„åœ°æ–¹éå¸¸äº®ï¼Œå› ç‚ºå¤–å¤ªç©ºçš„æ˜Ÿæ˜Ÿå’Œè¡Œæ˜Ÿéƒ½æœƒç…§äº®æˆ‘çš„å±…æ‰€ã€‚æœ‰æ™‚å€™é‚„èƒ½çœ‹åˆ°æ¼‚äº®çš„æµæ˜Ÿå’Œå½—æ˜Ÿå‘¢ï¼\n"
          ]
        }
      ],
      "source": [
        "reply = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\":\"system\", \"content\":\"ä½ æ˜¯éš»ä½åœ¨å¤–å¤ªç©ºçš„çŒ´å­\"},\n",
        "        {\"role\":\"user\", \"content\": \"ä½ ä½çš„åœ°æ–¹å¾ˆäº®å—ï¼Ÿ reply in ç¹é«”ä¸­æ–‡\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(reply.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuqEE9zwkxHx"
      },
      "source": [
        "### 7ï¸âƒ£ å¯«æˆå‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "48eLL4VEQGza"
      },
      "outputs": [],
      "source": [
        "def get_reply(messages):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model = \"gpt-3.5-turbo\",\n",
        "            messages = messages\n",
        "        )\n",
        "        reply = response.choices[0].message.content\n",
        "    except OpenAIError as err:\n",
        "        reply = f\"ç™¼ç”Ÿ {err.error.type} éŒ¯èª¤\\n{err.error.message}\"\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyB85LMUcHai"
      },
      "source": [
        "### 8ï¸âƒ£ ç°¡æ˜“çš„å°è«‡ç¨‹å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "aMBhPuFwcH4G",
        "outputId": "97fa68b6-b8aa-4e81-e3dc-bb4067ba4924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä½ èªªï¼šAI\n",
            "ã„Ÿå”‰ï¼šstands for Artificial Intelligence, which refers to the simulation of human intelligence processes by machines, especially computer systems. AI technologies include machine learning, natural language processing, and computer vision. AI is used in a wide range of applications, such as virtual assistants, autonomous vehicles, and medical diagnostics.\n",
            "\n",
            "ä½ èªªï¼šBERT\n",
            "ã„Ÿå”‰ï¼šBERT (Bidirectional Encoder Representations from Transformers) is a type of neural network architecture designed for natural language processing tasks. It utilizes transformer architecture to learn contextual representations of words in a bidirectional manner, making it highly effective for various NLP tasks such as text classification, named entity recognition, and question answering. BERT has achieved state-of-the-art results on many benchmarks in the field of NLP.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f520456ae461>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ä½ èªªï¼š\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    msg = input(\"ä½ èªªï¼š\")\n",
        "    if not msg.strip(): break\n",
        "    messages = [{\"role\":\"user\", \"content\":msg}]\n",
        "    reply = get_reply(messages)\n",
        "    print(f\"ã„Ÿå”‰ï¼š{reply}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xyG43Miczix"
      },
      "source": [
        "### 9ï¸âƒ£ è¨˜æ†¶å°è©±ç´€éŒ„çš„å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daLnk-UGczqX"
      },
      "outputs": [],
      "source": [
        "hist = []       # æ­·å²å°è©±ç´€éŒ„\n",
        "backtrace = 2   # è¨˜éŒ„å¹¾çµ„å°è©±\n",
        "\n",
        "def chat(sys_msg, user_msg):\n",
        "    hist.append({\"role\":\"user\", \"content\":user_msg})\n",
        "    reply = get_reply(hist\n",
        "                      + [{\"role\":\"system\", \"content\":sys_msg}])\n",
        "    while len(hist) >= 2 * backtrace: # è¶…éè¨˜éŒ„é™åˆ¶\n",
        "        hist.pop(0)                   # ç§»é™¤æœ€èˆŠç´€éŒ„\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply})\n",
        "    return reply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgQuQjVLc5wU"
      },
      "source": [
        "### ğŸ”Ÿ èƒ½æ¥çºŒå°è©±çš„ AI ç¨‹å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKjDWUWAc59I",
        "outputId": "728e863c-654c-4c67-d3c0-b2c183545ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ä½ å¸Œæœ›ã„Ÿå”‰æ‰®æ¼”ï¼šåœ°ç†å¤§å¸«\n",
            "\n",
            "ä½ èªªï¼šå°ç£åœ¨å“ªè£¡?\n",
            "åœ°ç†å¤§å¸«:å°ç£ä½æ–¼æ±äºçš„è¥¿å¤ªå¹³æ´‹è¥¿éƒ¨ï¼Œåœ°è™•åŒ—ç·¯23åº¦27åˆ†è‡³25åº¦56åˆ†ï¼Œæ±ç¶“119åº¦18åˆ†è‡³124åº¦34åˆ†ä¹‹é–“ã€‚å°ç£åŒ—è‡¨æ±æµ·ï¼ˆå¤ªå¹³æ´‹ä¸­çš„å—æµ·ï¼‰ï¼Œæ±æ¿±å¤ªå¹³æ´‹ï¼Œå—éš”å·´å£«æµ·å³½èˆ‡è²å¾‹è³“ç¾¤å³¶ç›¸æœ›ï¼Œè¥¿æ¿±è‡ºç£æµ·å³½èˆ‡ä¸­åœ‹å¤§é™¸ç›¸å°ã€‚å°ç£çš„åœ°ç†ä½ç½®éå¸¸ç‰¹æ®Šï¼Œæ˜¯æ±äºåœ°å€çš„é‡è¦äº¤é€šæ¨ç´ï¼Œä¹Ÿæ˜¯å¤ªå¹³æ´‹è¥¿éƒ¨çš„é‡è¦é–€æˆ¶ã€‚\n",
            "\n",
            "ä½ èªªï¼šé¢ç©æœ‰å¤šå¤§?\n",
            "åœ°ç†å¤§å¸«:å°ç£çš„ç¸½é¢ç©ç´„36,193å¹³æ–¹å…¬é‡Œã€‚é€™å€‹é¢ç©åŒ…å«äº†å°ç£æœ¬å³¶ä»¥åŠå—æµ·è«¸å³¶ï¼ˆæ¾æ¹–ç¾¤å³¶ã€é‡‘é–€ç¾¤å³¶ã€é¦¬ç¥–ç¾¤å³¶ç­‰ï¼‰ã€‚å°ç£æœ¬å³¶çš„é¢ç©ç´„æœ‰å°ç£ç¸½é¢ç©çš„97%ï¼Œç´„35,883å¹³æ–¹å…¬é‡Œã€‚\n",
            "\n",
            "ä½ èªªï¼š\n"
          ]
        }
      ],
      "source": [
        "sys_msg = input(\"ä½ å¸Œæœ›ã„Ÿå”‰æ‰®æ¼”ï¼š\")\n",
        "if not sys_msg.strip(): sys_msg = 'å°åŠ©ç†'\n",
        "print()\n",
        "while True:\n",
        "    msg = input(\"ä½ èªªï¼š\")\n",
        "    if not msg.strip(): break\n",
        "    reply = chat(sys_msg, msg)\n",
        "    print(f\"{sys_msg}:{reply}\\n\")\n",
        "hist = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAX-IFIYHrlH"
      },
      "source": [
        "### 1ï¸âƒ£1ï¸âƒ£ å®‰è£èˆ‡åŒ¯å…¥ google æœå°‹å¥—ä»¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htKR8b20udnQ",
        "outputId": "3ad574c9-4f1a-4229-a9d7-f0580aa89d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch-python-1.2.3.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.11.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2023.7.22)\n",
            "Building wheels for collected packages: googlesearch-python\n",
            "  Building wheel for googlesearch-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlesearch-python: filename=googlesearch_python-1.2.3-py3-none-any.whl size=4204 sha256=492352366b5c5513631da20e7c70977ea68fdb4fb0c9e95664d591acc13bcf6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/24/e9/6c225502948c629b01cc895f86406819281ef0da385f3eb669\n",
            "Successfully built googlesearch-python\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install googlesearch-python\n",
        "from googlesearch import search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx_Hs7E172Ko"
      },
      "source": [
        "### 1ï¸âƒ£2ï¸âƒ£ ä½¿ç”¨ google æœå°‹å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd1BRQ_m8UBx",
        "outputId": "488bf7fe-a081-41b1-c034-236a5dc970b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023å¹´NBAç¸½æ±ºè³½ - ç¶­åŸºç™¾ç§‘\n",
            "2023å¹´NBAç¸½æ±ºè³½ï¼ˆè‹±èªï¼š2023 NBA Finalsï¼‰æ˜¯2022â€“23 NBAè³½å­£çš„å† è»ç³»åˆ—è³½ï¼Œå°‡ç”±2023å¹´6æœˆ1æ—¥è‡³6æœˆ12æ—¥é€²è¡Œï¼Œç”±è¥¿å€ç¬¬ä¸€ç¨®å­ä¸¹ä½›é‡‘å¡Šå°æˆ°æ±å€ç¬¬å…«ç¨®å­é‚é˜¿å¯†ç†±ç«ï¼Œæ¯”è³½Â ...\n",
            "https://zh.wikipedia.org/zh-hant/2023%E5%B9%B4NBA%E7%B8%BD%E6%B1%BA%E8%B3%BD\n",
            "\n",
            "2023å¹´NBAå­£å¾Œè³½ - ç¶­åŸºç™¾ç§‘\n",
            "... NBAè³½å­£ä¾‹è¡Œè³½å®Œç•¢å¾Œèˆ‰è¡Œçš„ä¸ƒæˆ°å››å‹åˆ¶æ·˜æ±°è³½ï¼Œæœ¬å±†æ˜¯ç¬¬76å±†å­£å¾Œè³½ã€‚ 2023å¹´NBAå­£å¾Œè³½. è³½å­£, 2022â€“23. éšŠä¼æ•¸, 16. å† è», ä¸¹ä½›é‡‘å¡Š (1 title). å¤±åˆ©çƒéšŠ, é‚é˜¿å¯†ç†±ç« (7Â ...\n",
            "https://zh.wikipedia.org/zh-hant/2023%E5%B9%B4NBA%E5%AD%A3%E5%BE%8C%E8%B3%BD\n",
            "\n",
            "ä¸¹ä½›æ˜é‡‘é˜Ÿæ˜¯2023 å¹´NBA å† å†›-å®Œæ•´ä½“è‚²\n",
            "Jun 13, 2023 â€” ä¸¹ä½›æ˜é‡‘é˜Ÿåœ¨94 å¹´NBA æ€»å†³èµ›ç¬¬89 åœºæ¯”èµ›ä¸­ä»¥5-2023 å‡»è´¥è¿ˆé˜¿å¯†çƒ­ç«é˜Ÿï¼Œèµ¢å¾—äº†ä»–ä»¬æœ‰å²ä»¥æ¥çš„ç¬¬ä¸€ä¸ªNBA æ€»å† å†›ã€‚\n",
            "https://www.completesports.com/zh-CN/denver-nuggets-are-2023-nba-champions/\n",
            "\n",
            "ç‹ é…¸é‡‘å¡Šåªæ˜¯æ“Šæ•—3æ”¯é™„åŠ è³½çƒéšŠå¥ªå† ï¼åè¨˜è€…ç—›æ‰¹ï¼šå²ä¸Šæœ€ ...\n",
            "Jun 13, 2023 â€” 2022-2023è³½å­£NBAç¸½å† è»è³½æ­£å¼è½å¹•ï¼Œç”±ä¸¹ä½›é‡‘å¡Šåœ¨ç¬¬äº”æˆ°ä»¥94ï¼š89æ“Šæ•—é‚é˜¿å¯†ç†±ç«å°ç‹ã€‚ç³»åˆ—è³½4å‹1æ•—å¥ªå¾—éšŠå²46å¹´ä¾†é¦–åº§å† è»ï¼Œä¸éç¾åœ‹è¨˜è€…å¸•çˆ¾é¦¬Â ...\n",
            "https://tw.yahoo.com/today/%E7%8B%A0%E9%85%B8%E9%87%91%E5%A1%8A%E5%8F%AA%E6%98%AF%E6%93%8A%E6%95%973%E6%94%AF%E9%99%84%E5%8A%A0%E8%B3%BD%E7%90%83%E9%9A%8A%E5%A5%AA%E5%86%A0-%E5%90%8D%E8%A8%98%E8%80%85%E7%97%9B%E6%89%B9-%E5%8F%B2%E4%B8%8A%E6%9C%80%E6%B0%B4%E5%86%A0%E8%BB%8D-131053675.html\n",
            "\n",
            "ä¸¹ä½›é‡‘å¡Šé¦–æ¬¡è´å¾—NBAç¸½å† è»\n",
            "Jun 13, 2023 â€” æ˜ŸæœŸä¸€ï¼Œä¸¹ä½›é‡‘å¡ŠéšŠåœ¨ä¸»å ´ä»¥94-89æ“Šæ•—é‚é˜¿å¯†ç†±ç«éšŠï¼Œè´å¾—2022-23å¹´NBA ç¾åœ‹åœ‹å®¶ç±ƒçƒå”æœƒå† è»ã€‚ é‡‘å¡Šåœ¨ä¸ƒå ´å››å‹åˆ¶ç³»åˆ—è³½ä¸­ä»¥3-1é ˜å…ˆé€²å…¥é€™å ´æ¯”è³½ï¼Œä½†åœ¨Â ...\n",
            "https://www.voacantonese.com/a/denver-nuggets-win-first-ever-nba-championship-20230613/7135098.html\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for item in search(\n",
        "    \"NBA 2023 å† è»éšŠ\", advanced=True, num_results=3):\n",
        "    print(item.title)\n",
        "    print(item.description)\n",
        "    print(item.url)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndwQg9wVx7eN"
      },
      "source": [
        "### 1ï¸âƒ£3ï¸âƒ£ å°‡æœå°‹çµæœåŠ å…¥åˆ° content ä¸­"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47Ya7BkDucsR"
      },
      "outputs": [],
      "source": [
        "hist = []       # æ­·å²å°è©±ç´€éŒ„\n",
        "backtrace = 2   # è¨˜éŒ„å¹¾çµ„å°è©±\n",
        "\n",
        "def chat_w(sys_msg, user_msg, search_g = True):\n",
        "    web_res = []\n",
        "    if search_g == True: # ä»£è¡¨è¦æœå°‹ç¶²è·¯\n",
        "        content = \"ä»¥ä¸‹ç‚ºå·²ç™¼ç”Ÿçš„äº‹å¯¦ï¼š\\n\"\n",
        "        for res in search(user_msg, advanced=True,\n",
        "                          num_results=3, lang='zh-TW'):\n",
        "            content += f\"æ¨™é¡Œï¼š{res.title}\\n\" \\\n",
        "                       f\"æ‘˜è¦ï¼š{res.description}\\n\\n\"\n",
        "        content += \"è«‹ä¾ç…§ä¸Šè¿°äº‹å¯¦å›ç­”å•é¡Œ \\n\"\n",
        "        web_res = [{\"role\": \"user\", \"content\": content}]\n",
        "    web_res.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    while len(hist) >= 2 * backtrace: # è¶…éè¨˜éŒ„é™åˆ¶\n",
        "        hist.pop(0)  # ç§»é™¤æœ€èˆŠçš„ç´€éŒ„\n",
        "    reply_full = \"\"\n",
        "    for reply in get_reply(\n",
        "        hist                          # å…ˆæä¾›æ­·å²ç´€éŒ„\n",
        "        + web_res                     # å†æä¾›æœå°‹çµæœåŠç›®å‰è¨Šæ¯\n",
        "        + [{\"role\": \"system\", \"content\": sys_msg}]):\n",
        "        reply_full += reply           # è¨˜éŒ„åˆ°ç›®å‰ç‚ºæ­¢æ”¶åˆ°çš„è¨Šæ¯\n",
        "        yield reply                   # å‚³å›æœ¬æ¬¡æ”¶åˆ°çš„ç‰‡æ®µè¨Šæ¯\n",
        "    hist.append({\"role\": \"user\", \"content\": user_msg})\n",
        "    while len(hist) >= 2 * backtrace: # è¶…éè¨˜éŒ„é™åˆ¶\n",
        "        hist.pop(0)                   # ç§»é™¤æœ€èˆŠç´€éŒ„\n",
        "    hist.append({\"role\":\"assistant\", \"content\":reply_full})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ItD6pYlyMjS"
      },
      "source": [
        "### 1ï¸âƒ£4ï¸âƒ£ çªç ´æœå°‹é™åˆ¶çš„èŠå¤©æ©Ÿå™¨äºº"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZKP6M_fuvqv",
        "outputId": "29d7ae89-cc95-49b3-838f-9aefde0424f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ä½ èªªï¼šNBA 2023 å† è»éšŠæ˜¯èª°?\n",
            "å°åŠ©ç†ï¼š2023å¹´NBAå† è»éšŠæ˜¯ä¸¹ä½›é‡‘å¡ŠéšŠã€‚\n",
            "\n",
            "ä½ èªªï¼š\n"
          ]
        }
      ],
      "source": [
        "sys_msg = 'å°åŠ©ç†'\n",
        "\n",
        "while True:\n",
        "    msg = input(\"ä½ èªªï¼š\")\n",
        "    if not msg.strip(): break\n",
        "    print(f\"{sys_msg}ï¼š\", end = \"\")\n",
        "    for reply in chat_w(sys_msg, msg, search_g = True):\n",
        "        print(reply, end = \"\")\n",
        "    print('\\n')\n",
        "hist = []"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}